{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use a conv net trained from scratch a large amount of data is needed. This can be achieved by limiting the number of classes and augmenting the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick check to see how many images there are per class\n",
    "\n",
    "def count_images(file_path):\n",
    "    # Finds class folders, makes a list of classes, and counts how many images are in each class\n",
    "    import os\n",
    "    from pathlib import Path\n",
    "    \n",
    "    image_counter = []\n",
    "    class_names = []\n",
    "    \n",
    "    for class_name in sorted(os.listdir(file_path)):\n",
    "        # Exclude .DS_Store\n",
    "        if class_name != '.DS_Store':\n",
    "            \n",
    "            class_names.append(class_name)\n",
    "\n",
    "            # Make a Path to the class directory\n",
    "            class_dir = Path(file_path) / class_name\n",
    "\n",
    "            # Note that this is set to work with .png images and needs modification\n",
    "            # to work with other types\n",
    "            image_counter.append(len(os.listdir(class_dir)))\n",
    "                          \n",
    "    return image_counter, class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', '1', '2']\n",
      "[2171, 198, 2086]\n"
     ]
    }
   ],
   "source": [
    "train_path = '/Users/zplab/Desktop/VeraPythonScripts/vera_autofocus/microscope_images_3cat/train'\n",
    "train_counts, class_names = count_images(train_path)\n",
    "print(class_names)\n",
    "print(train_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', '1', '2']\n",
      "[2136, 198, 2121]\n"
     ]
    }
   ],
   "source": [
    "test_path = '/Users/zplab/Desktop/VeraPythonScripts/vera_autofocus/microscope_images_3cat/test'\n",
    "test_counts, class_names = count_images(test_path)\n",
    "print(class_names)\n",
    "print(test_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a lot of images, but only 198 for the acceptable class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(file_path, means, stds):\n",
    "    # Function loads a black and white .png image and transforms it into\n",
    "    # a tensor suitable for use with pytorch\n",
    "    # Inputs:\n",
    "    #    file_path: string path to the image (currently complete path)\n",
    "    #               PosixPaths also work\n",
    "    #    norms: list of 3 means from the model original training data,\n",
    "    #        corresponding to RGB\n",
    "    #    stds: list of 3 standard deviations (RGB) from training data\n",
    "\n",
    "    # This is intended to be a more getting into the nitty gritty method of importing images for use with pytorch\n",
    "    # Based on the tutorial available here:\n",
    "    # https://medium.com/@josh_2774/deep-learning-with-pytorch-9574e74d17ad\n",
    "\n",
    "    from PIL import Image\n",
    "    import numpy as np\n",
    "    import torch\n",
    "    \n",
    "    # Load the image\n",
    "    img = Image.open(file_path)\n",
    "    \n",
    "    # Re-size the image to 256 x 256\n",
    "    width, height = img.size\n",
    "    if width > height:\n",
    "        img.thumbnail((256, 1000000)) # Constrain width to 256 pixels, thumbnail adjusts heigh proportionally\n",
    "    else:\n",
    "        img.thumbnail((1000000, 256)) # Constrain height to 256 pixels\n",
    "        \n",
    "    # Crop out center 224 by 224\n",
    "    left_margin = (img.width-224)/2\n",
    "    bottom_margin = (img.height-224)/2\n",
    "    right_margin = left_margin + 224\n",
    "    top_margin = bottom_margin + 224\n",
    "    img = img.crop((left_margin, bottom_margin, right_margin, top_margin))\n",
    "\n",
    "    # Convert the image into a numpy array\n",
    "    img = np.array(img)\n",
    "    \n",
    "    # Divide by the max value to get range 0 to 1\n",
    "    img = img / np.ptp(img)\n",
    "    \n",
    "    Rm, Gm, Bm = means # provided mean\n",
    "    Rstd, Gstd, Bstd = stds # provided std\n",
    "    \n",
    "    # Make 3 normalized arrays from one 224 x 224 array\n",
    "    R = (img - Rm)/ Rstd\n",
    "    G = (img - Gm)/ Gstd\n",
    "    B = (img - Bm)/ Bstd\n",
    "    \n",
    "    # Stack the three normalized arrays to make an \"RGB\" image\n",
    "    img_RGB = np.stack([R, G, B])\n",
    "    \n",
    "    # Convert the array into a tensor\n",
    "    tensor_RGB = torch.from_numpy(img_RGB).type(torch.FloatTensor)\n",
    "    \n",
    "    return tensor_RGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def de_process_image(tensor, means, stds):\n",
    "    # Function takes a tensor corresponding to an image from pytorch and\n",
    "    # converts it back into a numpy array (may add PIL image). This is useful\n",
    "    # to check on what is being passed to the network at the end of the full import process\n",
    "    # Inputs:\n",
    "    #    tensor: pytorch tensor corresponding to an image\n",
    "    #    norms: list of 3 means from the model original training data,\n",
    "    #        corresponding to RGB\n",
    "    #    stds: list of 3 standard deviations (RGB) from training data\n",
    "    from PIL import Image\n",
    "    import numpy as np\n",
    "    import torch\n",
    "    \n",
    "    # Convert the tensor into a numpy array\n",
    "    img_RGB = torch.Tensor.numpy(tensor)\n",
    "\n",
    "    # Get the means and stds\n",
    "    Rm, Gm, Bm = means # provided mean\n",
    "    Rstd, Gstd, Bstd = stds # provided std\n",
    "    \n",
    "    # Take one 224 x 224 stack off the 3 x 224 x 224 \"RGB\" image\n",
    "    img = img_RGB[1, :, :]\n",
    "    \n",
    "    # Breakout the means and stds. These are different for each of\n",
    "    # the layers, I am making the assumption that the one I took out\n",
    "    # is red. This could cause problems if the mean and std for green\n",
    "    # or blue is very different.\n",
    "    Rm, Gm, Bm = means # provided mean\n",
    "    Rstd, Gstd, Bstd = stds # provided std\n",
    "    \n",
    "    # De-normalize using mean and std for red\n",
    "    img = img * Rstd + Rm\n",
    "    \n",
    "    # At this point I am only returning the de-normalized numpy array\n",
    "    # If a PIL image is desired code will need to be added to do that\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-a794ef545a10>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mwormDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m   \u001b[0;34m'Characterizes a dataset for PyTorch'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# Assumes that the images are sorted by class into folders, which are named\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# with the class name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "class wormDataset(data.Dataset):\n",
    "  'Characterizes a dataset for PyTorch'\n",
    "  def __init__(self, file_path, means, stds):\n",
    "    # Assumes that the images are sorted by class into folders, which are named\n",
    "    # with the class name\n",
    "        self.file_path = Path(file_path)\n",
    "        self.means = means\n",
    "        self.stds = stds\n",
    "        #Initialization\n",
    "        self.classes = [] # Empty list to append class names onto\n",
    "\n",
    "        # Indexed list of class_folder/image.png\n",
    "        #self.list_IDs = list_IDs\n",
    "        self.image_paths = []\n",
    "\n",
    "        # Find class folders on the file path\n",
    "        for class_name in sorted(os.listdir(file_path)):\n",
    "            # Use of sorted is important, numbered classes will import in order which is really helpful later\n",
    "\n",
    "            # Exclude .DS_Store\n",
    "            if class_name != '.DS_Store':\n",
    "\n",
    "                # Save the class name to the classes list\n",
    "                self.classes.append(class_name)\n",
    "\n",
    "                # Make a Path to the class directory\n",
    "                class_dir = self.file_path / class_name\n",
    "\n",
    "                # Note that this is set to work with .png images and needs modification\n",
    "                # to work with other types\n",
    "                for image in class_dir.glob('*.png'):\n",
    "                    # Add the path to the image to the list of image paths\n",
    "                    self.image_paths.append(image)\n",
    "\n",
    "\n",
    "  def __len__(self):\n",
    "        'Denotes the total number of samples'\n",
    "        return len(self.image_paths)\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "        'Generates one sample of data'\n",
    "        # Select sample\n",
    "\n",
    "        # Needs a list with all the filenames in the list\n",
    "        # Here, this is the name of the specific image + the enclosing class folder\n",
    "\n",
    "        # Uses the index to get class_folder/image_name\n",
    "        image_path = self.image_paths[index]\n",
    "\n",
    "        # Load data and get label\n",
    "        sample = process_image(image_path, self.means, self.stds)\n",
    "\n",
    "        # Convert the class folder into the string name of the class\n",
    "        class_name = str(image_path.parent.stem)\n",
    "        # Use this to convert the string name into the corresponding numerical label\n",
    "        label = self.classes.index(class_name)\n",
    "\n",
    "        return sample, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
