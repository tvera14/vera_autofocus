{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This resnet50 model was trained using 5 classes. This training process is documented in \"Custom Dataset Class Testing with Resnet50\", since it is when I was working out the better import process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick check to see how many images there are per class\n",
    "\n",
    "def count_images(file_path):\n",
    "    # Finds class folders, makes a list of classes, and counts how many images are in each class\n",
    "    import os\n",
    "    from pathlib import Path\n",
    "    \n",
    "    image_counter = []\n",
    "    \n",
    "    for class_name in os.listdir(file_path):\n",
    "        # Exclude .DS_Store\n",
    "        if class_name != '.DS_Store':\n",
    "\n",
    "            # Make a Path to the class directory\n",
    "            class_dir = Path(file_path) / class_name\n",
    "\n",
    "            # Note that this is set to work with .png images and needs modification\n",
    "            # to work with other types\n",
    "            image_counter.append(len(os.listdir(class_dir)))\n",
    "                          \n",
    "    return image_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[95, 298, 57, 95, 310]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_path = '/Users/zplab/Desktop/VeraPythonScripts/vera_autofocus/microscope_images/train'\n",
    "train_counts = count_images(train_path)\n",
    "train_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[100, 292, 60, 100, 348]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_path = '/Users/zplab/Desktop/VeraPythonScripts/vera_autofocus/microscope_images/test'\n",
    "test_counts = count_images(test_path)\n",
    "test_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected 5 classes in training data\n",
      "['slightly_out_neg', 'very_out_neg', 'acceptable', 'slightly_out_pos', 'very_out_pos']\n",
      "Train batch size = 10, test batch size = 10\n",
      "Trainloder length = 86, testloader length = 90\n"
     ]
    }
   ],
   "source": [
    "# Import the image processing functions and class\n",
    "from image_import import process_image, de_process_image, wormDataset\n",
    "\n",
    "# Import all needed libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms, models\n",
    "# These last two are used to save info about how the training progressed\n",
    "import pickle\n",
    "import datetime\n",
    "\n",
    "# Set the full path to the main image directory\n",
    "train_dir = '/Users/zplab/Desktop/VeraPythonScripts/vera_autofocus/microscope_images/train'\n",
    "test_dir = '/Users/zplab/Desktop/VeraPythonScripts/vera_autofocus/microscope_images/test'\n",
    "num_train = 10\n",
    "num_test = 10\n",
    "\n",
    "means = [0.485, 0.456, 0.406]\n",
    "stds = [0.229, 0.224, 0.225]\n",
    "\n",
    "traindata = wormDataset(train_dir, means, stds)\n",
    "testdata = wormDataset(test_dir, means, stds)\n",
    "\n",
    "# Load from the training and test sets\n",
    "trainloader = torch.utils.data.DataLoader(traindata, batch_size=num_train, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(testdata, batch_size=num_test, shuffle=True)\n",
    "\n",
    "# Get the classes\n",
    "class_names = traindata.classes\n",
    "print('Detected ' + str(len(class_names)) + ' classes in training data')\n",
    "print(class_names)\n",
    "\n",
    "# Print out how many images are in the trainloader and testloader\n",
    "print(\"Train batch size = \" + str(num_train) + ', test batch size = ' + str(num_test))\n",
    "print('Trainloder length = ' + str(len(trainloader)) + ', testloader length = ' + str(len(testloader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture \n",
    "\n",
    "# Load up the trained model\n",
    "model_path = '/Users/zplab/Desktop/VeraPythonScripts/vera_autofocus/compare_num_classes/resnet50_5cat.pth'\n",
    "model = torch.load(model_path)\n",
    "model.eval() # Put the model in eval mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on 900 test images: 74 %\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on all images in the test loader\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on ' + str(total) + ' test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model trained on 7 classes has accuracy of 67% after the same number of rounds of training. The model with 3 classes has >90%, but also never classifies anything as acceptable due to sample bias (3 acceptable images in a stack of 40, so many more out of focus than in focus).\n",
    "\n",
    "This 5 category model was trained when I was still assigning string names to the folders rather than numbering them, which makes a less intuitive confusion matrix. To overcome this I modified the confusion matrix code to re-order the columns and rows for:\n",
    "0) Very out neg\n",
    "1) Slightly out neg\n",
    "2) Acceptable\n",
    "3) Slightly out pos\n",
    "4) Very out pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['slightly_out_neg', 'very_out_neg', 'acceptable', 'slightly_out_pos', 'very_out_pos']\n"
     ]
    }
   ],
   "source": [
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_convert(class_names, label):\n",
    "    if class_names[label] == 'very_out_neg':\n",
    "        new_label = 0\n",
    "    elif class_names[label] == 'slightly_out_neg':\n",
    "        new_label = 1\n",
    "    elif class_names[label] == 'acceptable':\n",
    "        new_label = 2\n",
    "    elif class_names[label] == 'slightly_out_pos':\n",
    "        new_label = 3\n",
    "    else:\n",
    "        new_label = 4\n",
    "    return new_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[292.   0.   0.   0.   0.]\n",
      " [ 70.   0.  30.   0.   0.]\n",
      " [  3.   0.  57.   0.   0.]\n",
      " [  0.   0.  71.  28.   1.]\n",
      " [  0.   0.   3.  49. 296.]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on all images in the test loader\n",
    "confusion_matrix = np.zeros((5, 5))\n",
    "\n",
    "class_names = testdata.classes\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        # This is processing in batches, the number of things in images and labels is the\n",
    "        # the same as the batch size\n",
    "        images, labels = data\n",
    "        outputs = model(images)\n",
    "        predicted = torch.max(outputs.data, 1)\n",
    "        num_labels = labels.size(0)\n",
    "        total += num_labels\n",
    "        for i in range(num_labels): # Iterate through the labels in the batch\n",
    "            \n",
    "            # Increase the cell corresponding to the label / prediction pair by one\n",
    "            confusion_matrix[label_convert(class_names, labels[i]), label_convert(class_names, predicted.indices[i])] += 1\n",
    "            \n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images in folders:\n",
      "[100, 292, 60, 100, 348]\n",
      "\n",
      "Labels in Confusion Matrix:\n",
      "[292. 100.  60. 100. 348.]\n"
     ]
    }
   ],
   "source": [
    "# Check that the numbers in the confusion matrix make sense\n",
    "print('Images in folders:')\n",
    "print(test_counts)\n",
    "print('')\n",
    "\n",
    "print('Labels in Confusion Matrix:')\n",
    "print(np.sum(confusion_matrix, axis=1))\n",
    "\n",
    "# The numbers match, and one column has switched position consistent with the convert_label function working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make a nicer version of the confusion matrix with axis labels\n",
    "plt.title('7 Category Confusion Matrix')\n",
    "plt.ylabel('Labels (True Class)')\n",
    "plt.xlabel('Predicted')\n",
    "plt.imshow(confusion_matrix, cmap='hot', interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74.77777777777777\n"
     ]
    }
   ],
   "source": [
    "# Percent accurate\n",
    "percent_accurate = np.sum(np.diagonal(confusion_matrix)) / np.sum(confusion_matrix) * 100\n",
    "print(percent_accurate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.33333333333333337"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Row 2 is true acceptable, column 2 is predicted acceptable\n",
    "# Errors in which an acceptable image is mistaken for out of focus\n",
    "(np.sum(confusion_matrix[2,:]) - confusion_matrix[2,2]) / np.sum(confusion_matrix) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.555555555555555"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Errors in which an out of focus image is mistaken for acceptable\n",
    "(np.sum(confusion_matrix[:,2]) - confusion_matrix[2,2]) / np.sum(confusion_matrix) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.88888888888889\n"
     ]
    }
   ],
   "source": [
    "# Percent of failure errors\n",
    "percent_failure = (np.sum(confusion_matrix[2,:]) + np.sum(confusion_matrix[:,2]) - (2 * confusion_matrix[2,2])) / np.sum(confusion_matrix) * 100\n",
    "print(percent_failure)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 5 category model has a higher accuracy rate overall (74.7%) than the 7 category model (66%). However, the rate of failure errors are comparable at 10.7% in the 7 category model and 11.8% in the 5 category model. However, the rate of mistaking an in focus image for out of focus in the 5 category model is still 1% or lower, so this is good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15.666666666666668"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Errors in which the predicted class is a neighbor of the true class\n",
    "# Subset the confusion matrix and take the diagonals to get the cells on either side of the main diagonal\n",
    "# (one class off vs. accurate predictions)\n",
    "neighbors_pos = np.diagonal(confusion_matrix[1:, :3])\n",
    "np.sum(neighbors_pos) / np.sum(confusion_matrix) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.3333333333333335"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neighbors_neg = np.diagonal(confusion_matrix[:3, 1:])\n",
    "np.sum(neighbors_neg) / np.sum(confusion_matrix) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19.0\n"
     ]
    }
   ],
   "source": [
    "percent_neighbor = (np.sum(neighbors_pos) + np.sum(neighbors_neg)) / np.sum(confusion_matrix) * 100 \n",
    "print(percent_neighbor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In both the 5 category and 7 category models, there is a tendency for more positive than negative neighbor errors. The number of neighbor errors in the 5 category model appears to be greater, however, I think the main cause is that with 7 categories there are more ways to be wrong that aren't a neighbor error. The 7 category model has lots of these \"other\" errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0., 57.,  0.,  0.])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Errors in which the model gets the direction wrong\n",
    "# Thinks the plane of focus is above best focus when it is below, and vice-versa\n",
    "# These are on the upper right to lower left diagonal, get this by flipping the array\n",
    "np.diagonal(np.fliplr(confusion_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "percent_opposite = (np.sum(np.diagonal(np.fliplr(confusion_matrix))) - confusion_matrix[2,2]) / np.sum(confusion_matrix) * 100\n",
    "print(percent_opposite)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are ZERO opposite errors in the 5 category model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-5.666666666666657\n"
     ]
    }
   ],
   "source": [
    "percent_other = 100 - percent_failure - percent_neighbor - percent_opposite - percent_accurate\n",
    "print(percent_other)\n",
    "# As of right now I have no idea which one of my measurements is off, need ot figure this out before relying on results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "bars = ['Accurate', 'Failure', 'Neighbor', 'Opposite', 'Other']\n",
    "y_pos = np.arange(len(bars))\n",
    "plt.bar(y_pos, [percent_accurate, percent_failure, percent_neighbor, percent_opposite, percent_other])\n",
    "plt.title('Results by Category')\n",
    "plt.ylabel('% of Total Predictions')\n",
    "plt.xticks(y_pos, bars)\n",
    "plt.ylim(0, 100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
