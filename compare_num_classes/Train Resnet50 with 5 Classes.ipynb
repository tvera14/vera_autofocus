{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Re-training Resnet50 with 5 classes in order to get ordered, numbered folders. I found that the wormDataset wasn't always bringing the folders in in the same order as the class numbering system, which is just MASSIVELY annoying to deal with when using the model - the prediction indices don't nicely correspond to the classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick check to see how many images there are per class\n",
    "\n",
    "def count_images(file_path):\n",
    "    # Finds class folders, makes a list of classes, and counts how many images are in each class\n",
    "    import os\n",
    "    from pathlib import Path\n",
    "    \n",
    "    image_counter = []\n",
    "    class_names = []\n",
    "    \n",
    "    for class_name in sorted(os.listdir(file_path)):\n",
    "        # Exclude .DS_Store\n",
    "        if class_name != '.DS_Store':\n",
    "            \n",
    "            class_names.append(class_name)\n",
    "\n",
    "            # Make a Path to the class directory\n",
    "            class_dir = Path(file_path) / class_name\n",
    "\n",
    "            # Note that this is set to work with .png images and needs modification\n",
    "            # to work with other types\n",
    "            image_counter.append(len(os.listdir(class_dir)))\n",
    "                          \n",
    "    return image_counter, class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', '1', '2', '3', '4']\n",
      "[298, 95, 57, 95, 310]\n"
     ]
    }
   ],
   "source": [
    "train_path = '/Users/zplab/Desktop/VeraPythonScripts/vera_autofocus/microscope_images/train'\n",
    "train_counts, class_names = count_images(train_path)\n",
    "print(class_names)\n",
    "print(train_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', '1', '2', '3', '4']\n",
      "[292, 100, 60, 100, 348]\n"
     ]
    }
   ],
   "source": [
    "test_path = '/Users/zplab/Desktop/VeraPythonScripts/vera_autofocus/microscope_images/test'\n",
    "test_counts, class_names = count_images(test_path)\n",
    "print(class_names)\n",
    "print(test_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected 5 classes in training data\n",
      "['0', '1', '2', '3', '4']\n",
      "Train batch size = 10, test batch size = 10\n",
      "Trainloder length = 86, testloader length = 90\n"
     ]
    }
   ],
   "source": [
    "# Import the image processing functions and class\n",
    "from image_import import process_image, de_process_image, wormDataset\n",
    "\n",
    "# Import all needed libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms, models\n",
    "# These last two are used to save info about how the training progressed\n",
    "import pickle\n",
    "import datetime\n",
    "\n",
    "# Set the full path to the main image directory\n",
    "train_dir = '/Users/zplab/Desktop/VeraPythonScripts/vera_autofocus/microscope_images/train'\n",
    "test_dir = '/Users/zplab/Desktop/VeraPythonScripts/vera_autofocus/microscope_images/test'\n",
    "num_train = 10\n",
    "num_test = 10\n",
    "\n",
    "means = [0.485, 0.456, 0.406]\n",
    "stds = [0.229, 0.224, 0.225]\n",
    "\n",
    "traindata = wormDataset(train_dir, means, stds)\n",
    "testdata = wormDataset(test_dir, means, stds)\n",
    "\n",
    "# Load from the training and test sets\n",
    "trainloader = torch.utils.data.DataLoader(traindata, batch_size=num_train, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(testdata, batch_size=num_test, shuffle=True)\n",
    "\n",
    "# Get the classes\n",
    "class_names = traindata.classes\n",
    "print('Detected ' + str(len(class_names)) + ' classes in training data')\n",
    "print(class_names)\n",
    "\n",
    "# Print out how many images are in the trainloader and testloader\n",
    "print(\"Train batch size = \" + str(num_train) + ', test batch size = ' + str(num_test))\n",
    "print('Trainloder length = ' + str(len(trainloader)) + ', testloader length = ' + str(len(testloader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture \n",
    "# Prevent printing out the model architecture\n",
    "# Check if cuda is available, and set pytorch to run on GPU or CPU as appropriate\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print('Cuda available, running on GPU')\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print('Cuda is not available, running on CPU')\n",
    "    # Give the user a message so they know what is going on\n",
    "\n",
    "model = models.resnet50(pretrained=True)\n",
    "#print(model) \n",
    "# Printing the model shows some of the internal layers, not expected to\n",
    "# understand these but neat to see\n",
    "\n",
    "# Freeze the pre-trained layers, no need to update featue detection\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Get the number of features the model expects in the final fully connected layer, this is different\n",
    "# in different models\n",
    "num_ftrs = model.fc.in_features\n",
    "\n",
    "# Re-define the final fully connected layer (model.fc, fc = fully connected)\n",
    "model.fc = nn.Sequential(nn.Linear(num_ftrs, 512), # 2048 inputs to 512 outputs \n",
    "                                 nn.ReLU(),\n",
    "                                 nn.Dropout(0.2),\n",
    "                                 # The next line needs to be modified for the number of classes\n",
    "                                 # in the data set. For the microscope images I currently have \n",
    "                                 # five classes, so there are 5 outputs\n",
    "                                 nn.Linear(512, 5), # 512 inputs to 5 outputs\n",
    "                                 nn.LogSoftmax(dim=1))\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.fc.parameters(), lr=0.003)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2.. Train loss: 2.895.. Test loss: 1.266.. Test accuracy: 0.736\n",
      "Epoch 1/2.. Train loss: 1.196.. Test loss: 0.838.. Test accuracy: 0.697\n",
      "Epoch 1/2.. Train loss: 0.705.. Test loss: 0.669.. Test accuracy: 0.764\n",
      "Epoch 1/2.. Train loss: 0.765.. Test loss: 0.701.. Test accuracy: 0.747\n",
      "Epoch 1/2.. Train loss: 0.794.. Test loss: 0.594.. Test accuracy: 0.743\n",
      "Epoch 1/2.. Train loss: 0.546.. Test loss: 0.530.. Test accuracy: 0.733\n",
      "Epoch 1/2.. Train loss: 0.592.. Test loss: 0.545.. Test accuracy: 0.808\n",
      "Epoch 1/2.. Train loss: 0.563.. Test loss: 0.407.. Test accuracy: 0.853\n",
      "Epoch 2/2.. Train loss: 0.685.. Test loss: 0.673.. Test accuracy: 0.741\n",
      "Epoch 2/2.. Train loss: 0.786.. Test loss: 0.412.. Test accuracy: 0.848\n",
      "Epoch 2/2.. Train loss: 0.764.. Test loss: 0.522.. Test accuracy: 0.777\n"
     ]
    }
   ],
   "source": [
    "# Train the network\n",
    "epochs = 2\n",
    "steps = 0\n",
    "running_loss = 0\n",
    "print_every = 10\n",
    "train_losses, test_losses, accuracy_tracker = [], [], []\n",
    "for epoch in range(epochs):\n",
    "    for inputs, labels in trainloader:\n",
    "        steps += 1\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        logps = model.forward(inputs)\n",
    "        loss = criterion(logps, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        if steps % print_every == 0:\n",
    "            test_loss = 0\n",
    "            accuracy = 0\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                for inputs, labels in testloader:\n",
    "                    inputs = inputs.to(device)\n",
    "                    labels = labels.to(device)\n",
    "                    logps = model.forward(inputs)\n",
    "                    batch_loss = criterion(logps, labels)\n",
    "                    test_loss += batch_loss.item()\n",
    "                    \n",
    "                    ps = torch.exp(logps)\n",
    "                    top_p, top_class = ps.topk(1, dim=1)\n",
    "                    equals = top_class == labels.view(*top_class.shape)\n",
    "                    accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n",
    "            train_losses.append(running_loss/len(trainloader))\n",
    "            test_losses.append(test_loss/len(testloader)) \n",
    "            accuracy_tracker.append(accuracy/len(testloader))                     \n",
    "            print(f\"Epoch {epoch+1}/{epochs}.. \"\n",
    "                  f\"Train loss: {running_loss/print_every:.3f}.. \"\n",
    "                  f\"Test loss: {test_loss/len(testloader):.3f}.. \"\n",
    "                  f\"Test accuracy: {accuracy/len(testloader):.3f}\")\n",
    "            running_loss = 0\n",
    "            model.train()\n",
    "torch.save(model, 'resnet50_5cat.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
