{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In each image stack, there are 44 images and only 3 are considered \"acceptable\" focus. This means the \"acceptable\" class has a much smaller population than out of focus classes. In previous rounds of training the model I did not correct for this, allowing the difference in population size to bias the training. In the 3 category model (below, acceptable, and above) this had a strong effect causing the model to miss every single acceptable image despite the model's apparent high accuracy. This bias is not as marked in the 5 and 7 category models since the out of focus images are split into more separate classes, but there are still more images in each out of focus class than in the acceptable class. In this notebook I train the model on a set of images in which the bias has been corrected to see if it improves accuracy overall and accuracy in identifying acceptable images as acceptable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick check to see how many images there are per class\n",
    "\n",
    "def count_images(file_path):\n",
    "    # Finds class folders, makes a list of classes, and counts how many images are in each class\n",
    "    import os\n",
    "    from pathlib import Path\n",
    "    \n",
    "    image_counter = []\n",
    "    class_names = []\n",
    "    \n",
    "    for class_name in sorted(os.listdir(file_path)):\n",
    "        # Exclude .DS_Store\n",
    "        if class_name != '.DS_Store':\n",
    "            \n",
    "            class_names.append(class_name)\n",
    "\n",
    "            # Make a Path to the class directory\n",
    "            class_dir = Path(file_path) / class_name\n",
    "\n",
    "            # Note that this is set to work with .png images and needs modification\n",
    "            # to work with other types\n",
    "            image_counter.append(len(os.listdir(class_dir)))\n",
    "                          \n",
    "    return image_counter, class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', '1', '2', '3', '4']\n",
      "[298, 95, 57, 95, 310]\n"
     ]
    }
   ],
   "source": [
    "train_path = '/Users/zplab/Desktop/VeraPythonScripts/vera_autofocus/microscope_images_5cat/train'\n",
    "train_counts, class_names = count_images(train_path)\n",
    "print(class_names)\n",
    "print(train_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', '1', '2', '3', '4']\n",
      "[292, 100, 60, 100, 348]\n"
     ]
    }
   ],
   "source": [
    "test_path = '/Users/zplab/Desktop/VeraPythonScripts/vera_autofocus/microscope_images_5cat/test'\n",
    "test_counts, class_names = count_images(test_path)\n",
    "print(class_names)\n",
    "print(test_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the test images, there are 60 acceptable samples compared to 348 and 292 in the two most out of focus classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected 5 classes in training data\n",
      "['0', '1', '2', '3', '4']\n",
      "Traindata length = 855, testdata length = 900\n"
     ]
    }
   ],
   "source": [
    "# Import the image processing functions and class\n",
    "from image_import import process_image, de_process_image, wormDataset\n",
    "\n",
    "# Import all needed libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms, models\n",
    "# These last two are used to save info about how the training progressed\n",
    "import pickle\n",
    "import datetime\n",
    "\n",
    "# Set the full path to the main image directory\n",
    "train_dir = '/Users/zplab/Desktop/VeraPythonScripts/vera_autofocus/microscope_images_5cat/train'\n",
    "test_dir = '/Users/zplab/Desktop/VeraPythonScripts/vera_autofocus/microscope_images_5cat/test'\n",
    "num_train = 10\n",
    "num_test = 10\n",
    "\n",
    "means = [0.485, 0.456, 0.406]\n",
    "stds = [0.229, 0.224, 0.225]\n",
    "\n",
    "traindata = wormDataset(train_dir, means, stds)\n",
    "testdata = wormDataset(test_dir, means, stds)\n",
    "\n",
    "# Get the classes\n",
    "class_names = traindata.classes\n",
    "print('Detected ' + str(len(class_names)) + ' classes in training data')\n",
    "print(class_names)\n",
    "\n",
    "# Print out how many images are in the trainloader and testloader\n",
    "print('Traindata length = ' + str(len(traindata)) + ', testdata length = ' + str(len(testdata)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train batch size = 10, test batch size = 10\n",
      "Trainloder length = 86, testloader length = 90\n"
     ]
    }
   ],
   "source": [
    "# Load using the non-corrected set for comparison\n",
    "# Load from the training and test sets\n",
    "trainloader = torch.utils.data.DataLoader(traindata, batch_size=num_train, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(testdata, batch_size=num_test, shuffle=True)\n",
    "\n",
    "# Print out how many images are in the trainloader and testloader\n",
    "print(\"Train batch size = \" + str(num_train) + ', test batch size = ' + str(num_test))\n",
    "print('Trainloder length = ' + str(len(trainloader)) + ', testloader length = ' + str(len(testloader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 292, 4: 348, 3: 100, 2: 60, 1: 100}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Iterate through images in the test loader to see what labels (corresponding to classes) they have\n",
    "label_dict = {}\n",
    "for data in testloader:\n",
    "    images, labels = data\n",
    "    for label in labels:\n",
    "        # Convert the label into a number\n",
    "        label = torch.Tensor.numpy(label)\n",
    "        label = label.item()\n",
    "        if label in label_dict:\n",
    "            label_dict[label] += 1\n",
    "        else:\n",
    "            label_dict[label] = 1\n",
    "label_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code for the balance correcting sampler is heavily based on this repo:\n",
    "https://github.com/ufoym/imbalanced-dataset-sampler\n",
    "\n",
    "Basically, the sampler is a data structure that takes the dataset, and then the sampler(dataset) is passed to the dataloader. I re-wrote the sampler to accept the wormDataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils import data\n",
    "\n",
    "\n",
    "class wormDatasetSampler(torch.utils.data.sampler.Sampler):\n",
    "    \"\"\"Samples elements randomly from a given list of indices for imbalanced dataset\n",
    "    Arguments:\n",
    "        indices (list, optional): a list of indices\n",
    "        num_samples (int, optional): number of samples to draw\n",
    "        \n",
    "    To use the sampler, add an argument to the DataLoader sampler = wormDatasetSampler(wormDataset)\n",
    "    This will pass the weights for the labels to the Dataloader\n",
    "    Note that shuffle must be false, if shuffling is desired that needs to be part of the sampler\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dataset, indices=None, num_samples=None):\n",
    "\n",
    "        # Make a set of indices to iterate through\n",
    "        self.indices = list(range(len(dataset)))\n",
    "\n",
    "        # Get the number of samples in the dataset\n",
    "        self.num_samples = len(self.indices)\n",
    "\n",
    "        # Make a dictionary with labels as keys and number of samples with that label as values\n",
    "        label_to_count = {}\n",
    "        for idx in self.indices:\n",
    "            label = self._get_label(dataset, idx)\n",
    "            if label in label_to_count:\n",
    "                label_to_count[label] += 1\n",
    "            else:\n",
    "                label_to_count[label] = 1\n",
    "\n",
    "        # weight for each sample\n",
    "        weights = [1.0 / label_to_count[self._get_label(dataset, idx)]\n",
    "                   for idx in self.indices]\n",
    "\n",
    "        self.weights = torch.DoubleTensor(weights)\n",
    "        # I think these weights are what is passed on to the DataLoader, presumably it knows what to do from there\n",
    "\n",
    "    def _get_label(self, dataset, idx):\n",
    "    \t# Get the label from the dataset\n",
    "        # In the wormDataset, each sample is a 1, 2 tensor with an array representing the image + the class\n",
    "        # tensor[image_array, class_label]\n",
    "        sample = dataset[idx]\n",
    "        label = sample[1]\n",
    "        return label\n",
    "\n",
    "        #image_import.wormDataset\n",
    "\n",
    "    def __iter__(self):\n",
    "        \n",
    "        # The sampler has to specify how to iterate through itself\n",
    "        return (self.indices[i] for i in torch.multinomial(\n",
    "            self.weights, self.num_samples, replacement=True))     \n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train batch size = 10, test batch size = 10\n",
      "Trainloader length = 86, testloader length = 90\n"
     ]
    }
   ],
   "source": [
    "# Re-load the data, this time with the sampler enclosing the dataset\n",
    "trainloader = torch.utils.data.DataLoader(traindata, sampler = wormDatasetSampler(traindata), batch_size=num_train, shuffle=False)\n",
    "testloader = torch.utils.data.DataLoader(testdata, sampler = wormDatasetSampler(testdata), batch_size=num_test, shuffle=False)\n",
    "# Shuffle has to be set to False when using a sampler. If you want shuffling it needs to happen in the sampler\n",
    "\n",
    "# Print out how many images are in the trainloader and testloader\n",
    "print(\"Train batch size = \" + str(num_train) + ', test batch size = ' + str(num_test))\n",
    "print('Trainloader length = ' + str(len(trainloader)) + ', testloader length = ' + str(len(testloader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 183, 2: 172, 1: 174, 3: 200, 4: 171}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This code block currently doesn't work, the wormDataset has issues with iterating over itself\n",
    "# Iterate through images in the test loader to see what labels (corresponding to classes) they have\n",
    "label_dict = {}\n",
    "for data in testloader:\n",
    "    images, labels = data\n",
    "    for label in labels:\n",
    "        # Convert the label into a number\n",
    "        label = torch.Tensor.numpy(label)\n",
    "        label = label.item()\n",
    "        if label in label_dict:\n",
    "            label_dict[label] += 1\n",
    "        else:\n",
    "            label_dict[label] = 1\n",
    "label_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the data has been sampled using wormDatasetSampler, there are a similar number of samples per class and population size will not be a source of bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture \n",
    "# Prevent printing out the model architecture\n",
    "# Check if cuda is available, and set pytorch to run on GPU or CPU as appropriate\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print('Cuda available, running on GPU')\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print('Cuda is not available, running on CPU')\n",
    "    # Give the user a message so they know what is going on\n",
    "\n",
    "model = models.resnet50(pretrained=True)\n",
    "#print(model) \n",
    "# Printing the model shows some of the internal layers, not expected to\n",
    "# understand these but neat to see\n",
    "\n",
    "# Freeze the pre-trained layers, no need to update featue detection\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Get the number of features the model expects in the final fully connected layer, this is different\n",
    "# in different models\n",
    "num_ftrs = model.fc.in_features\n",
    "\n",
    "# Re-define the final fully connected layer (model.fc, fc = fully connected)\n",
    "model.fc = nn.Sequential(nn.Linear(num_ftrs, 512), # 2048 inputs to 512 outputs \n",
    "                                 nn.ReLU(),\n",
    "                                 nn.Dropout(0.2),\n",
    "                                 # The next line needs to be modified for the number of classes\n",
    "                                 # in the data set. For the microscope images I currently have \n",
    "                                 # five classes, so there are 5 outputs\n",
    "                                 nn.Linear(512, 5), # 512 inputs to 5 outputs\n",
    "                                 nn.LogSoftmax(dim=1))\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.fc.parameters(), lr=0.003)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2.. Train loss: 2.689.. Test loss: 2.563.. Test accuracy: 0.239\n"
     ]
    }
   ],
   "source": [
    "# Train the network\n",
    "epochs = 2\n",
    "steps = 0\n",
    "running_loss = 0\n",
    "print_every = 10\n",
    "train_losses, test_losses, accuracy_tracker = [], [], []\n",
    "for epoch in range(epochs):\n",
    "    for inputs, labels in trainloader:\n",
    "        steps += 1\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        logps = model.forward(inputs)\n",
    "        loss = criterion(logps, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        if steps % print_every == 0:\n",
    "            test_loss = 0\n",
    "            accuracy = 0\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                for inputs, labels in testloader:\n",
    "                    inputs = inputs.to(device)\n",
    "                    labels = labels.to(device)\n",
    "                    logps = model.forward(inputs)\n",
    "                    batch_loss = criterion(logps, labels)\n",
    "                    test_loss += batch_loss.item()\n",
    "                    \n",
    "                    ps = torch.exp(logps)\n",
    "                    top_p, top_class = ps.topk(1, dim=1)\n",
    "                    equals = top_class == labels.view(*top_class.shape)\n",
    "                    accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n",
    "            train_losses.append(running_loss/len(trainloader))\n",
    "            test_losses.append(test_loss/len(testloader)) \n",
    "            accuracy_tracker.append(accuracy/len(testloader))                     \n",
    "            print(f\"Epoch {epoch+1}/{epochs}.. \"\n",
    "                  f\"Train loss: {running_loss/print_every:.3f}.. \"\n",
    "                  f\"Test loss: {test_loss/len(testloader):.3f}.. \"\n",
    "                  f\"Test accuracy: {accuracy/len(testloader):.3f}\")\n",
    "            running_loss = 0\n",
    "            model.train()\n",
    "torch.save(model, 'resnet50_5cat_unbiased.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
